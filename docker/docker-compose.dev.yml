# ChordMiniApp Docker Compose Configuration
# For local development and testing

version: '3.8'

services:
  # Frontend - Next.js Application
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      target: runner
      args:
        - NEXT_PUBLIC_PYTHON_API_URL=http://backend:8080
    container_name: chordmini-frontend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_PYTHON_API_URL=http://backend:8080
      - NEXT_TELEMETRY_DISABLED=1
      - PORT=3000
      - HOSTNAME=0.0.0.0
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - chordmini-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Backend - Python Flask ML Service
  backend:
    build:
      context: ./python_backend
      dockerfile: Dockerfile
      target: runtime
    container_name: chordmini-backend
    ports:
      - "8080:8080"
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=False
      - FLASK_APP=app.py
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PRODUCTION_MODE=true
      - DEFAULT_BEAT_MODEL=beat-transformer
      - DEFAULT_CHORD_MODEL=chord-cnn-lstm
      - MAX_CONTENT_LENGTH=104857600
      - UPLOAD_TIMEOUT=600
      # Rate limiting configuration
      - REDIS_URL=redis://redis:6379/0
      # Model configuration
      - USE_BEAT_TRANSFORMER=true
      - USE_CHORD_CNN_LSTM=true
      - USE_BTC_SL=true
      - USE_BTC_PL=true
    volumes:
      # Optional: Mount models directory for development
      # - ./python_backend/models:/app/models:ro
      # Mount cache directory for model caching
      - backend-cache:/tmp/model_cache
      - backend-logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - chordmini-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 90s

  # Redis for rate limiting and caching
  redis:
    image: redis:7-alpine
    container_name: chordmini-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - chordmini-network
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s

networks:
  chordmini-network:
    driver: bridge
    name: chordmini-network

volumes:
  backend-cache:
    name: chordmini-backend-cache
    driver: local
  backend-logs:
    name: chordmini-backend-logs
    driver: local
  redis-data:
    name: chordmini-redis-data
    driver: local
