# ChordMiniApp Production Docker Compose Configuration
# For production deployment with optimized settings

version: '3.8'

services:
  # Frontend - Next.js Application (Production)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      target: runner
      args:
        - NODE_ENV=production
    image: chordmini-frontend:latest
    container_name: chordmini-frontend-prod
    ports:
      - "80:3000"
      - "443:3000"  # If using SSL termination
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_PYTHON_API_URL=http://backend:8080
      - NEXT_TELEMETRY_DISABLED=1
      - PORT=3000
      - HOSTNAME=0.0.0.0
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - chordmini-prod-network
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backend - Python Flask ML Service (Production)
  backend:
    build:
      context: ./python_backend
      dockerfile: Dockerfile
      target: runtime
    image: chordmini-backend:latest
    container_name: chordmini-backend-prod
    ports:
      - "8080:8080"
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=False
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - DEFAULT_BEAT_MODEL=beat-transformer
      - DEFAULT_CHORD_MODEL=chord-cnn-lstm
      - MAX_CONTENT_LENGTH=104857600
      - UPLOAD_TIMEOUT=600
      - LOG_LEVEL=INFO
      - ENABLE_MODEL_CACHE=true
      - CACHE_DIR=/tmp/model_cache
    volumes:
      - backend-cache:/tmp/model_cache
      - backend-logs:/var/log
    networks:
      - chordmini-prod-network
    restart: always
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Redis for production caching
  # Set REDIS_PASSWORD environment variable before running: export REDIS_PASSWORD=your_secure_password
  redis:
    image: redis:7-alpine
    container_name: chordmini-redis-prod
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - chordmini-prod-network
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  chordmini-prod-network:
    driver: bridge
    name: chordmini-prod-network

volumes:
  backend-cache:
    name: chordmini-backend-cache-prod
  backend-logs:
    name: chordmini-backend-logs-prod
  redis-data:
    name: chordmini-redis-data-prod
